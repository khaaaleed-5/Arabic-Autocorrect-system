{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:51:29.599018Z","iopub.status.busy":"2024-04-30T19:51:29.598568Z","iopub.status.idle":"2024-04-30T19:51:51.736920Z","shell.execute_reply":"2024-04-30T19:51:51.735758Z","shell.execute_reply.started":"2024-04-30T19:51:29.598971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-30 19:51:40.467481: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-30 19:51:40.467586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-30 19:51:40.646173: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n","import torch\n","from datasets import Dataset\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{},"source":["# Load Model"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:51:51.741008Z","iopub.status.busy":"2024-04-30T19:51:51.739840Z","iopub.status.idle":"2024-04-30T19:52:12.198526Z","shell.execute_reply":"2024-04-30T19:52:12.197193Z","shell.execute_reply.started":"2024-04-30T19:51:51.740953Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e53dd3e457ce49b78fab5e16119c9d22","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3011e8a90bf5423eb24423d18262b4cf","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b7e1ca88c39428891da36b8788216df","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa726e851074432689c28286b83c13e0","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af65606e6dbb406bb812b34c7efd0868","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/2.25G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(250002, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (distance_embedding): Embedding(1023, 64)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (transform_act_fn): GELUActivation()\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=1024, out_features=250002, bias=True)\n","    )\n","  )\n",")\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"Twitter/twhin-bert-large\")\n","model = AutoModelForMaskedLM.from_pretrained(\"Twitter/twhin-bert-large\").to('cuda')\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15, return_tensors='pt')\n","\n","print(model)"]},{"cell_type":"markdown","metadata":{},"source":["## Run inference"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:52:12.200375Z","iopub.status.busy":"2024-04-30T19:52:12.200002Z","iopub.status.idle":"2024-04-30T19:52:13.319908Z","shell.execute_reply":"2024-04-30T19:52:13.318816Z","shell.execute_reply.started":"2024-04-30T19:52:12.200343Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"name":"stdout","output_type":"stream","text":["Masked token 1:\n","Token: المدرسة, Score: 21.685152053833008\n","Token: السماء, Score: 21.205638885498047\n","Token: كم, Score: 20.726768493652344\n","Token: الأمام, Score: 20.532899856567383\n","Token: نفسي, Score: 20.517539978027344\n"]}],"source":["# Input text with masked tokens\n","input_text = \"انا اسمي علي, اذهب كل يوم الي <mask> لكي اتعلم.\"\n","# input_text = \"My name is ali, eachday i go to <mask>.\"\n","\n","# Tokenize input text\n","tokenized_input = tokenizer(input_text, return_tensors='pt').to('cuda')\n","\n","# Mask the token corresponding to the masked word\n","mask_token_index = torch.where(tokenized_input['input_ids'] == tokenizer.mask_token_id)\n","input_ids = tokenized_input['input_ids'].clone()\n","input_ids[mask_token_index] = tokenizer.mask_token_id\n","\n","# Generate predictions\n","with torch.no_grad():\n","    outputs = model(input_ids) # fORWARD PASS\n","\n","# Extract predictions for the masked tokens\n","masked_token_logits = outputs.logits[mask_token_index]\n","\n","# Get the top-n predicted token IDs and scores\n","n = 5  # Number of top predictions to retrieve\n","top_n_scores, top_n_indices = torch.topk(masked_token_logits, n, dim=-1)\n","\n","# Decode the top-n predicted token IDs into text\n","top_n_predicted_tokens = []\n","for i in range(len(mask_token_index[0])):\n","    top_n_predicted_tokens.append([tokenizer.decode(token_id.item()) for token_id in top_n_indices[i]])\n","\n","# Print the top-n predicted tokens and their scores\n","for i, (tokens, scores) in enumerate(zip(top_n_predicted_tokens, top_n_scores)):\n","    print(f\"Masked token {i+1}:\")\n","    for token, score in zip(tokens, scores):\n","        print(f\"Token: {token}, Score: {score.item()}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:52:13.322778Z","iopub.status.busy":"2024-04-30T19:52:13.322436Z","iopub.status.idle":"2024-04-30T19:52:23.756422Z","shell.execute_reply":"2024-04-30T19:52:23.754599Z","shell.execute_reply.started":"2024-04-30T19:52:13.322747Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>targe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>بين أستوديوهات ورزازات وصحراء مرزوكة وآثار ولي...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>قررت النجمة الأمريكية أوبرا وينفري ألا يقتصر ع...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>أخبارنا المغربية الوزاني تصوير الشملالي ألهب ا...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>اخبارنا المغربية قال ابراهيم الراشدي محامي سعد...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>تزال صناعة الجلود في المغرب تتبع الطريقة التقل...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>111723</th>\n","      <td>اللاعب تأخر في العودة إلى التداريب والمدرب غاض...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>111724</th>\n","      <td>المشرف العام لحسنية أكادير قال إنه سيغادر الفر...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>111725</th>\n","      <td>نسب إليه نتائج الوداد وصحوة الرجاء وآخر صيحاته...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>111726</th>\n","      <td>ستحتضن الرباط في الفترة مابين يوليوز المقبل دو...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>111727</th>\n","      <td>رضخ أحمد أهمو رئيس أمل تيزنيت لكرة القدم لضغوط...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>111728 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                     text  targe\n","0       بين أستوديوهات ورزازات وصحراء مرزوكة وآثار ولي...      0\n","1       قررت النجمة الأمريكية أوبرا وينفري ألا يقتصر ع...      0\n","2       أخبارنا المغربية الوزاني تصوير الشملالي ألهب ا...      0\n","3       اخبارنا المغربية قال ابراهيم الراشدي محامي سعد...      0\n","4       تزال صناعة الجلود في المغرب تتبع الطريقة التقل...      0\n","...                                                   ...    ...\n","111723  اللاعب تأخر في العودة إلى التداريب والمدرب غاض...      4\n","111724  المشرف العام لحسنية أكادير قال إنه سيغادر الفر...      4\n","111725  نسب إليه نتائج الوداد وصحوة الرجاء وآخر صيحاته...      4\n","111726  ستحتضن الرباط في الفترة مابين يوليوز المقبل دو...      4\n","111727  رضخ أحمد أهمو رئيس أمل تيزنيت لكرة القدم لضغوط...      4\n","\n","[111728 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('/kaggle/input/arabic-classification/arabic_dataset_classifiction.csv/arabic_dataset_classifiction.csv')\n","df"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:52:23.759359Z","iopub.status.busy":"2024-04-30T19:52:23.758723Z","iopub.status.idle":"2024-04-30T19:52:23.775687Z","shell.execute_reply":"2024-04-30T19:52:23.774140Z","shell.execute_reply.started":"2024-04-30T19:52:23.759305Z"},"trusted":true},"outputs":[],"source":["def preprocess(sentence: str):\n","    sentence = sentence.replace('أ', 'ا').replace('إ', 'ا').replace('آ', 'ا')\n","    \n","    for char in sentence:\n","        if char not in 'ابتثجحخدذرزسشصضطظعغفقكلمنهويءئؤىة ':\n","            sentence = sentence.replace(char, \"\")\n","\n","    return sentence\n","\n","def tokenize(x):\n","    tokenized_inputs = tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=128) # input\n","#     tokenized_inputs[\"word_ids\"] = [tokenized_inputs.word_ids(i) for i in range(len(tokenized_inputs[\"input_ids\"]))]\n","    \n","    return {**tokenized_inputs}\n","\n","def adjust_threshold(my_dict:dict):\n","    words_freq = list(my_dict.values())\n","    mean = np.mean(words_freq)\n","    std_dev = np.std(words_freq)\n","    k = 1\n","    threshold = mean + 0.01 * std_dev\n","\n","    return int(threshold)\n","\n","\n","def preprocess_input(input_text:str,my_dict:dict,threshold):\n","    words = input_text.split()\n","    masked_arr = []\n","    \n","    #generate mask \n","    for idx,word in enumerate(words):\n","        freq = my_dict.get(word,0)\n","        if freq < threshold:\n","            arr = words.copy()\n","            arr[idx] = \"<mask>\"\n","            sentence = \" \".join(arr)\n","            masked_arr.append(sentence)\n","\n","    return masked_arr \n","\n","def data_vocab(dataframe):\n","    words_freq = Counter()\n","    for index, row in dataframe.iterrows():\n","        sentence = row['text']\n","        words = sentence.split()\n","        words_freq.update(words)\n","    return words_freq\n","\n","#conatenate \n","def concatenate(sentences,masked):\n","    true_sentence = []\n","    masks_ids = {}\n","\n","    #get mask index in each sentence\n","    for idx_sentence,sentence in enumerate(sentences):\n","        words = sentence.split()\n","        for idx_word,word in enumerate(words):\n","            if word == '<mask>':\n","                masks_ids[idx_sentence] = idx_word \n","                \n","    #concatenate the true sentence\n","    for idx_sentence,sentence in enumerate(sentences):\n","        words = sentence.split()\n","        for idx_word,word in enumerate(words):\n","            if words[idx_word] not in true_sentence:\n","                if idx_word not in masks_ids.values():\n","                    true_sentence += [words[idx_word]]\n","                else:\n","                    if masked:  # Check if masked list is not empty\n","                        true_sentence.append(masked.pop(0))\n","    true_sentence = ' '.join(true_sentence)\n","    \n","    return true_sentence"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:52:23.777776Z","iopub.status.busy":"2024-04-30T19:52:23.777367Z","iopub.status.idle":"2024-04-30T19:53:00.899972Z","shell.execute_reply":"2024-04-30T19:53:00.898790Z","shell.execute_reply.started":"2024-04-30T19:52:23.777739Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce5b196abe354ede8b85255adc85096f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 800\n","    })\n","    test: Dataset({\n","        features: ['input_ids', 'attention_mask'],\n","        num_rows: 200\n","    })\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Preprocess\n","df = df.drop(columns=['targe'], axis=1)\n","\n","# drop null values\n","df = df.dropna()\n","\n","# drop duplicates\n","df = df.drop_duplicates()\n","\n","# remove any letter but arabic\n","df['text'] = df['text'].apply(lambda x: preprocess(x))\n","\n","# remove sentences that are less than 5 words\n","df['text'] = df['text'].apply(lambda x: x if len(x.split()) > 5 else None)\n","df = df.dropna().reset_index(drop=True)\n","\n","# Vocab of the dataset\n","words_freq = data_vocab(df)\n","\n","# Convert to hugging face Dataset\n","dataset = Dataset.from_pandas(df[:1000]) # 10K rows only\n","\n","# Mapping columns\n","dataset = dataset.map(tokenize, batched=True, remove_columns=['text'])\n","\n","dataset = dataset.train_test_split(test_size=0.2, shuffle=True)\n","\n","dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:53:00.901571Z","iopub.status.busy":"2024-04-30T19:53:00.901260Z","iopub.status.idle":"2024-04-30T19:53:02.133573Z","shell.execute_reply":"2024-04-30T19:53:02.132378Z","shell.execute_reply.started":"2024-04-30T19:53:00.901544Z"},"trusted":true},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./model\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=1e-5,\n","    num_train_epochs=3,\n","    weight_decay=5e-4,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    push_to_hub=True,\n","    logging_steps=10,\n","    eval_steps=10,\n","    push_to_hub_token=\"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\",\n","    report_to=\"wandb\"\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    data_collator=data_collator,\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:53:02.136880Z","iopub.status.busy":"2024-04-30T19:53:02.136193Z","iopub.status.idle":"2024-04-30T19:59:16.167380Z","shell.execute_reply":"2024-04-30T19:59:16.166377Z","shell.execute_reply.started":"2024-04-30T19:53:02.136820Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240430_195359-jwo0vw4l</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/ai-for-good/huggingface/runs/jwo0vw4l' target=\"_blank\">sunny-snowball-6</a></strong> to <a href='https://wandb.ai/ai-for-good/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/ai-for-good/huggingface' target=\"_blank\">https://wandb.ai/ai-for-good/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/ai-for-good/huggingface/runs/jwo0vw4l' target=\"_blank\">https://wandb.ai/ai-for-good/huggingface/runs/jwo0vw4l</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [150/150 04:55, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.574800</td>\n","      <td>2.238981</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.387300</td>\n","      <td>2.345582</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.414200</td>\n","      <td>2.285141</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=150, training_loss=2.4738434982299804, metrics={'train_runtime': 373.6758, 'train_samples_per_second': 6.423, 'train_steps_per_second': 0.401, 'total_flos': 559619617996800.0, 'train_loss': 2.4738434982299804, 'epoch': 3.0})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T19:59:16.169013Z","iopub.status.busy":"2024-04-30T19:59:16.168667Z","iopub.status.idle":"2024-04-30T20:00:26.868801Z","shell.execute_reply":"2024-04-30T20:00:26.867701Z","shell.execute_reply.started":"2024-04-30T19:59:16.168977Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"699f2c66380148c6bdc41a1c35716965","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37a8e590f00146648d90ecae3a862d2e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/2.25G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adf353fdbfd947ea9188d56c1d12e48f","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.save_model(\"/kaggle/working/model\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T20:00:26.872553Z","iopub.status.busy":"2024-04-30T20:00:26.872211Z","iopub.status.idle":"2024-04-30T20:00:30.810773Z","shell.execute_reply":"2024-04-30T20:00:30.809634Z","shell.execute_reply.started":"2024-04-30T20:00:26.872526Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForMaskedLM.from_pretrained(\"/kaggle/working/model\").to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["threshold = adjust_threshold(words_freq)\n","def predict(input_text):\n","    # Tokenize input text\n","    tokenized_input = tokenizer(input_text, return_tensors='pt').to('cuda')\n","\n","    # Mask the token corresponding to the masked word\n","    mask_token_index = torch.where(tokenized_input['input_ids'] == tokenizer.mask_token_id)\n","\n","    # Generate predictions\n","    with torch.no_grad():\n","        outputs = model(**tokenized_input) # fORWARD PASS\n","\n","    # Extract predicted token ID\n","    predicted_token_id = torch.argmax(outputs.logits[mask_token_index]).item()\n","\n","    # Decode the predicted token ID\n","    predicted_token = tokenizer.decode(predicted_token_id)\n","    \n","    return predicted_token\n","\n","def pipeline(input_text):\n","    arr_input = preprocess_input(input_text,words_freq,threshold)\n","    masked = []\n","    for sentence in arr_input:\n","        mask = predict(sentence)\n","        masked.append(mask)\n","    \n","    true_sentence = concatenate(arr_input,masked)\n","    \n","    return true_sentence\n","    \n","        "]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T20:13:36.110504Z","iopub.status.busy":"2024-04-30T20:13:36.110070Z","iopub.status.idle":"2024-04-30T20:13:36.160725Z","shell.execute_reply":"2024-04-30T20:13:36.159630Z","shell.execute_reply.started":"2024-04-30T20:13:36.110473Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["المصرية\n"]}],"source":["# Test the model\n","input_text = \"قررت النجمة الامركية اوبرا وينفري الا يقتر عملها على الفن\"\n","true_sentence = pipeline(input_text)\n","\n","print(true_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1164193,"sourceId":1950688,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
